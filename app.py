# app.py
# Importando as bibliotecas necess√°rias
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import io
import os
import re
import numpy as np

# Configura√ß√£o para evitar problemas de GUI em ambientes de servidor
import matplotlib
matplotlib.use('Agg')

# Importa√ß√µes do LangChain e Google
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain.tools import tool
from langchain_core.messages import HumanMessage, AIMessage

# Importa√ß√µes para o RAG com ChromaDB
from langchain_chroma import Chroma
from langchain.schema import Document

# --------------------------------------------------------------------------------
# Configura√ß√£o e Constantes
# --------------------------------------------------------------------------------

# Diret√≥rios para salvar arquivos tempor√°rios e o banco de dados vetorial
TEMP_DATA_FILE = "temp_df.pkl"
CHROMA_DB_DIR = "chroma_db_eda"
PLOTS_DIR = "plots"

# Cria o diret√≥rio de plots se n√£o existir
if not os.path.exists(PLOTS_DIR):
    os.makedirs(PLOTS_DIR)

# --------------------------------------------------------------------------------
# Fun√ß√µes Auxiliares
# --------------------------------------------------------------------------------

def sanitize_filename(name: str) -> str:
    """Substitui caracteres inv√°lidos em nomes de arquivos por underscores."""
    s = re.sub(r'[\\/*?:"<>|()]', "_", name)
    return "_".join(s.split())

# --------------------------------------------------------------------------------
# L√ìGICA DO RAG (MEM√ìRIA DE LONGO PRAZO)
# --------------------------------------------------------------------------------

@st.cache_resource
def initialize_rag(_api_key):
    """Inicializa o banco de dados vetorial ChromaDB e os embeddings."""
    try:
        embeddings_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=_api_key)
        vector_store = Chroma(persist_directory=CHROMA_DB_DIR, embedding_function=embeddings_model)
        return vector_store
    except Exception as e:
        st.error(f"Erro ao inicializar o RAG: {e}")
        return None

def save_analysis_to_rag(vector_store, question: str, answer: str):
    """Salva uma an√°lise (pergunta e resposta) no banco de dados vetorial."""
    if vector_store:
        try:
            document = Document(page_content=f"Pergunta do Usu√°rio: {question}\n\nConclus√£o do Agente: {answer}", metadata={"source": "AgentAnalysis"})
            vector_store.add_documents([document])
            print(f"INFO: An√°lise salva no RAG com sucesso.")
        except Exception as e:
            print(f"ERRO: Falha ao salvar an√°lise no RAG: {e}")

# --------------------------------------------------------------------------------
# FERRAMENTAS DO AGENTE
# --------------------------------------------------------------------------------

@tool
def search_past_analyses(query: str) -> str:
    """
    Pesquisa em an√°lises e conclus√µes passadas para responder a uma pergunta.
    Use esta ferramenta PRIMEIRO se a pergunta do usu√°rio for sobre 'conclus√µes', 'resumos anteriores' ou 'an√°lises j√° feitas'.
    """
    if "vector_store" in st.session_state and st.session_state.vector_store:
        results = st.session_state.vector_store.similarity_search(query, k=3)
        if not results:
            return "Nenhuma an√°lise anterior relevante foi encontrada."
        context = "\n\n---\n\n".join([doc.page_content for doc in results])
        return f"An√°lises passadas encontradas que podem ser relevantes:\n\n{context}"
    return "O banco de dados de an√°lises passadas n√£o est√° dispon√≠vel."

@tool
def get_dataframe_info(query: str) -> str:
    """
    Retorna um resumo completo do DataFrame ATUAL, incluindo colunas, tipos de dados, valores ausentes e estat√≠sticas descritivas.
    Esta deve ser a PRIMEIRA ferramenta a ser usada para entender um novo conjunto de dados.
    """
    try:
        df = pd.read_pickle(TEMP_DATA_FILE)
    except FileNotFoundError:
        return "Erro: Nenhum arquivo de dados est√° carregado. Pe√ßa ao usu√°rio para carregar um arquivo CSV."
    buffer = io.StringIO()
    df.info(buf=buffer)
    info_str = buffer.getvalue()
    return f"Resumo do Arquivo Atual:\n{info_str}\n\nEstat√≠sticas Descritivas:\n{df.describe().to_string()}"

@tool
def get_all_variability(query: str) -> str:
    """
    Calcula o desvio padr√£o e a vari√¢ncia para TODAS as colunas num√©ricas do arquivo ATUAL.
    Use para perguntas sobre 'variabilidade', 'dispers√£o', 'desvio padr√£o' ou 'vari√¢ncia' dos dados.
    """
    try:
        df = pd.read_pickle(TEMP_DATA_FILE)
    except FileNotFoundError:
        return "Erro: Nenhum arquivo de dados est√° carregado."
    numeric_df = df.select_dtypes(include=np.number)
    if numeric_df.empty:
        return "Nenhuma coluna num√©rica encontrada no arquivo para calcular a variabilidade."
    variability = pd.DataFrame({'Desvio Padr√£o': numeric_df.std(), 'Vari√¢ncia': numeric_df.var()}).reset_index().rename(columns={'index': 'Coluna'})
    return f"A variabilidade para as colunas num√©ricas √© a seguinte:\n{variability.to_markdown(index=False)}"

@tool
def plot_distribution(column_name: str) -> str:
    """
    Cria e salva um gr√°fico de distribui√ß√£o (histograma ou contagem) para uma √öNICA coluna espec√≠fica do arquivo ATUAL.
    """
    try:
        df = pd.read_pickle(TEMP_DATA_FILE)
    except FileNotFoundError:
        return "Erro: Nenhum arquivo de dados est√° carregado."
    if column_name not in df.columns:
        return f"Erro: A coluna '{column_name}' n√£o foi encontrada. Colunas dispon√≠veis: {', '.join(df.columns)}"
    fig, ax = plt.subplots(figsize=(10, 6))
    safe_column_name = sanitize_filename(column_name)
    if pd.api.types.is_numeric_dtype(df[column_name]):
        sns.histplot(df[column_name], kde=True, ax=ax)
        ax.set_title(f'Distribui√ß√£o de {column_name}')
        file_name = f"dist_hist_{safe_column_name}.png"
    else:
        top_n = 20
        order = df[column_name].value_counts().nlargest(top_n).index
        sns.countplot(y=df[column_name], ax=ax, order=order)
        ax.set_title(f'Contagem para {column_name} (Top {top_n})')
        file_name = f"dist_count_{safe_column_name}.png"
    plt.tight_layout()
    file_path = os.path.join(PLOTS_DIR, file_name)
    plt.savefig(file_path)
    plt.close(fig)
    return f"Gr√°fico de distribui√ß√£o salvo como '{file_path}'."

@tool
def plot_scatterplot(column_x: str, column_y: str) -> str:
    """
    Cria e salva um gr√°fico de dispers√£o (scatterplot) para visualizar a rela√ß√£o entre DUAS colunas NUM√âRICAS.
    """
    try:
        df = pd.read_pickle(TEMP_DATA_FILE)
    except FileNotFoundError:
        return "Erro: Nenhum arquivo de dados est√° carregado."
    if column_x not in df.columns or column_y not in df.columns:
        return f"Erro: Uma ou ambas as colunas n√£o foram encontradas. Colunas dispon√≠veis: {', '.join(df.columns)}"
    if not pd.api.types.is_numeric_dtype(df[column_x]) or not pd.api.types.is_numeric_dtype(df[column_y]):
        return f"Erro: Ambas as colunas devem ser num√©ricas para um gr√°fico de dispers√£o."
    
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.scatterplot(data=df, x=column_x, y=column_y, ax=ax)
    ax.set_title(f'Rela√ß√£o entre {column_x} e {column_y}')
    plt.tight_layout()
    
    safe_x = sanitize_filename(column_x)
    safe_y = sanitize_filename(column_y)
    file_name = f"scatter_{safe_x}_vs_{safe_y}.png"
    file_path = os.path.join(PLOTS_DIR, file_name)
    plt.savefig(file_path)
    plt.close(fig)
    return f"Gr√°fico de dispers√£o salvo como '{file_path}'."

@tool
def plot_boxplot(numeric_column: str, categorical_column: str) -> str:
    """
    Cria e salva um boxplot para comparar a distribui√ß√£o de uma coluna NUM√âRICA atrav√©s das categorias de uma coluna CATEG√ìRICA.
    """
    try:
        df = pd.read_pickle(TEMP_DATA_FILE)
    except FileNotFoundError:
        return "Erro: Nenhum arquivo de dados est√° carregado."
    if numeric_column not in df.columns or categorical_column not in df.columns:
        return f"Erro: Uma ou ambas as colunas n√£o foram encontradas. Colunas dispon√≠veis: {', '.join(df.columns)}"
    if not pd.api.types.is_numeric_dtype(df[numeric_column]):
        return f"Erro: A coluna '{numeric_column}' deve ser num√©rica para um boxplot."

    fig, ax = plt.subplots(figsize=(12, 7))
    sns.boxplot(data=df, x=numeric_column, y=categorical_column, ax=ax)
    ax.set_title(f'Distribui√ß√£o de {numeric_column} por {categorical_column}')
    plt.tight_layout()

    safe_num = sanitize_filename(numeric_column)
    safe_cat = sanitize_filename(categorical_column)
    file_name = f"boxplot_{safe_num}_by_{safe_cat}.png"
    file_path = os.path.join(PLOTS_DIR, file_name)
    plt.savefig(file_path)
    plt.close(fig)
    return f"Boxplot salvo como '{file_path}'."

@tool
def plot_correlation_heatmap() -> str:
    """
    Calcula e salva um mapa de calor (heatmap) da matriz de correla√ß√£o para TODAS as colunas num√©ricas do arquivo. N√£o precisa de argumentos.
    """
    try:
        df = pd.read_pickle(TEMP_DATA_FILE)
    except FileNotFoundError:
        return "Erro: Nenhum arquivo de dados est√° carregado."
        
    numeric_df = df.select_dtypes(include=np.number)
    if numeric_df.shape[1] < 2:
        return "Erro: S√£o necess√°rias pelo menos duas colunas num√©ricas para gerar um mapa de calor de correla√ß√£o."
        
    corr = numeric_df.corr()
    fig, ax = plt.subplots(figsize=(16, 12))
    sns.heatmap(corr, annot=False, cmap='coolwarm', ax=ax)
    ax.set_title('Mapa de Calor de Correla√ß√£o das Vari√°veis Num√©ricas')
    plt.tight_layout()

    file_name = "correlation_heatmap.png"
    file_path = os.path.join(PLOTS_DIR, file_name)
    plt.savefig(file_path)
    plt.close(fig)
    return f"Mapa de calor de correla√ß√£o salvo como '{file_path}'."

# --- FERRAMENTA ATUALIZADA ---
@tool
def plot_lineplot(time_column: str, value_column: str) -> str:
    """
    Cria e salva um gr√°fico de linhas para mostrar a tend√™ncia de uma coluna NUM√âRICA ao longo de uma coluna de TEMPO ou SEQUENCIAL.
    Se o dataset for muito grande, uma amostra dos dados ser√° usada para gerar o gr√°fico mais rapidamente.
    """
    try:
        df = pd.read_pickle(TEMP_DATA_FILE)
    except FileNotFoundError:
        return "Erro: Nenhum arquivo de dados est√° carregado."
    
    if time_column not in df.columns or value_column not in df.columns:
        return f"Erro: Uma ou ambas as colunas n√£o foram encontradas. Colunas dispon√≠veis: {', '.join(df.columns)}"
    if not pd.api.types.is_numeric_dtype(df[value_column]):
        return f"Erro: A coluna de valor '{value_column}' deve ser num√©rica."

    # --- L√ìGICA DE OTIMIZA√á√ÉO ---
    sample_size = 50000
    plot_df = df
    title_note = ""
    if len(df) > sample_size:
        plot_df = df.sample(n=sample_size, random_state=42).sort_values(by=time_column)
        title_note = f"\n(usando amostra de {sample_size} pontos)"
    # --- FIM DA L√ìGICA ---

    fig, ax = plt.subplots(figsize=(12, 6))
    sns.lineplot(data=plot_df, x=time_column, y=value_column, ax=ax)
    ax.set_title(f'Tend√™ncia de {value_column} ao longo de {time_column}{title_note}')
    plt.tight_layout()

    safe_time = sanitize_filename(time_column)
    safe_value = sanitize_filename(value_column)
    file_name = f"lineplot_{safe_value}_over_{safe_time}.png"
    file_path = os.path.join(PLOTS_DIR, file_name)
    plt.savefig(file_path)
    plt.close(fig)
    return f"Gr√°fico de linhas salvo como '{file_path}'."
# --- FIM DA FERRAMENTA ATUALIZADA ---

# --------------------------------------------------------------------------------
# L√ìGICA PRINCIPAL DA APLICA√á√ÉO STREAMLIT
# --------------------------------------------------------------------------------

st.set_page_config(page_title="Agente de An√°lise de Dados", layout="wide")
st.title("ü§ñ Agente de An√°lise de Dados com Gemini")

with st.sidebar:
    st.header("1. Configura√ß√£o")
    api_key_input = st.text_input("Google API Key ou a que consta no documento enviado por email", type="password", help="Insira sua chave de API do Google Gemini.")
    if api_key_input:
        st.session_state.GOOGLE_API_KEY = api_key_input

    st.header("2. Carregue seus Dados")
    uploaded_file = st.file_uploader("Escolha um arquivo CSV", type="csv")
    if uploaded_file:
        try:
            df = pd.read_csv(uploaded_file)
            df.to_pickle(TEMP_DATA_FILE)
            st.success(f"Arquivo '{uploaded_file.name}' carregado!")
            st.session_state.messages = [{"role": "assistant", "content": f"Ol√°! Analisando o arquivo '{uploaded_file.name}'. Como posso ajudar?"}]
        except Exception as e:
            st.error(f"Erro ao carregar o arquivo: {e}")
            if os.path.exists(TEMP_DATA_FILE): os.remove(TEMP_DATA_FILE)

    if os.path.exists(TEMP_DATA_FILE):
        st.header("3. Exemplos de Perguntas")
        st.info(
            "**B√°sicas:**\n"
            "- Descreva os dados.\n"
            "- Qual a distribui√ß√£o da coluna 'Amount'?\n"
            "- Qual a variabilidade dos dados?\n\n"
            "**Novos Gr√°ficos:**\n"
            "- Qual a rela√ß√£o entre 'V10' e 'V12'?\n"
            "- Compare 'Amount' por 'Class' com um boxplot.\n"
            "- Mostre o mapa de calor de correla√ß√£o.\n"
            "- Mostre a tend√™ncia de 'Amount' ao longo de 'Time'."
        )
    else:
        st.warning("Carregue um arquivo CSV e insira sua API Key para come√ßar.")

# --- Inicializa√ß√£o do Agente e da Mem√≥ria ---

# --- Ferramentas Dispon√≠veis para o Agente Utilizar ---
available_tools = [
    get_dataframe_info, 
    get_all_variability, 
    plot_distribution, 
    search_past_analyses,
    plot_scatterplot,
    plot_boxplot,
    plot_correlation_heatmap,
    plot_lineplot
]

prompt_template = ChatPromptTemplate.from_messages(
    [
        ("system", """Voc√™ √© um cientista de dados assistente. Sua principal tarefa √© analisar o arquivo CSV carregado na sess√£o ATUAL.

        **Seu Fluxo de Trabalho e Ferramentas:**
        1.  **Entendimento Inicial:** Ao analisar um novo arquivo, SEMPRE comece usando `get_dataframe_info`.
        2.  **Mem√≥ria:** Se a pergunta for sobre 'conclus√µes' ou 'an√°lises passadas', use `search_past_analyses`.
        3.  **An√°lise Univariada (1 vari√°vel):**
            - Para um resumo de variabilidade (desvio padr√£o, vari√¢ncia), use `get_all_variability`.
            - Para visualizar a distribui√ß√£o de UMA coluna, use `plot_distribution`.
        4.  **An√°lise Bivariada (2 vari√°veis):**
            - Para ver a rela√ß√£o entre DUAS colunas NUM√âRICAS, use `plot_scatterplot`.
            - Para comparar uma coluna NUM√âRICA entre as categorias de uma coluna CATEG√ìRICA, use `plot_boxplot`.
            - Para ver a tend√™ncia de um valor NUM√âRICO ao longo do TEMPO/sequ√™ncia, use `plot_lineplot`.
        5.  **An√°lise Multivariada (+2 vari√°veis):**
            - Para visualizar a correla√ß√£o entre TODAS as colunas num√©ricas, use `plot_correlation_heatmap`.
        
        Responda em portugu√™s, de forma clara. Ao gerar um gr√°fico, avise o usu√°rio e informe o nome do arquivo. Forne√ßa um par√°grafo de 'Conclus√£o' ap√≥s an√°lises complexas."""),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)

if "messages" not in st.session_state:
    st.session_state.messages = []

if "agent_executor" not in st.session_state and "GOOGLE_API_KEY" in st.session_state:
    try:
        llm = ChatGoogleGenerativeAI(model="models/gemini-2.5-pro", temperature=0.4, google_api_key=st.session_state.GOOGLE_API_KEY, convert_system_message_to_human=True)
        agent = create_tool_calling_agent(llm, available_tools, prompt_template)
        st.session_state.agent_executor = AgentExecutor(agent=agent, tools=available_tools, verbose=True, handle_parsing_errors=True, return_intermediate_steps=True)
        st.session_state.vector_store = initialize_rag(st.session_state.GOOGLE_API_KEY)
    except Exception as e:
        st.error(f"Erro ao inicializar o agente do LangChain: {e}")
        if "agent_executor" in st.session_state: del st.session_state.agent_executor

# --- √Årea de Chat Principal ---

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "images" in message:
            for img_path in message["images"]:
                if os.path.exists(img_path):
                    st.image(img_path)

if os.path.exists(TEMP_DATA_FILE) and "agent_executor" in st.session_state:
    if prompt := st.chat_input("Fa√ßa sua pergunta sobre o arquivo..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("O agente est√° pensando e analisando, dependendo do tipo e quantidade de dados analisados pode demorar at√© alguns minutos..."):
                try:
                    chat_history = [HumanMessage(content=msg["content"]) if msg["role"] == "user" else AIMessage(content=msg["content"]) for msg in st.session_state.messages[:-1]]
                    response = st.session_state.agent_executor.invoke({"input": prompt, "chat_history": chat_history})
                    agent_response_text = response.get('output', 'N√£o foi poss√≠vel gerar uma resposta.')
                    assistant_message = {"role": "assistant", "content": agent_response_text, "images": []}

                    if "intermediate_steps" in response:
                        for _, observation in response["intermediate_steps"]:
                            filenames = re.findall(r"'(.*?\.png)'", str(observation))
                            for filename in filenames:
                                if os.path.exists(filename):
                                    assistant_message["images"].append(filename)
                    
                    st.markdown(agent_response_text)
                    for img_path in assistant_message["images"]:
                        st.image(img_path)
                    
                    st.session_state.messages.append(assistant_message)
                    
                    if len(agent_response_text) > 100:
                        save_analysis_to_rag(st.session_state.vector_store, prompt, agent_response_text)

                except Exception as e:
                    error_message = f"Ocorreu um erro inesperado: {e}"
                    st.error(error_message)
                    st.session_state.messages.append({"role": "assistant", "content": error_message})
else:
    st.info("Bem-vindo! Por favor, carregue um arquivo CSV e insira sua API Key na barra lateral para iniciar a an√°lise.")